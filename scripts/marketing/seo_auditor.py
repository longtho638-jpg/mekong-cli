#!/usr/bin/env python3
"""
ðŸ” Autonomous SEO Auditor
=========================
Crawls the documentation directory and identifies SEO gaps:
1. Missing meta descriptions
2. Low keyword density
3. Broken internal links
4. Missing Alt tags in images
"""

import os
import re
from pathlib import Path
from typing import Any, Dict, List

import yaml


class SEOAuditor:
    def __init__(self, docs_path: str = "apps/docs/src/content/docs"):
        self.docs_path = Path(docs_path)
        self.results = []

    def run_audit(self) -> List[Dict[str, Any]]:
        """Audits all markdown files in the docs directory."""
        files = list(self.docs_path.glob("**/*.md"))
        print(f"ðŸš€ Auditing {len(files)} documentation pages...")

        for file_path in files:
            audit_entry = self._audit_file(file_path)
            if audit_entry["issues"]:
                self.results.append(audit_entry)

        return self.results

    def _audit_file(self, path: Path) -> Dict[str, Any]:
        content = path.read_text()
        issues = []

        # 1. Parse Frontmatter
        frontmatter = {}
        fm_match = re.search(r'^---\s*\n(.*?)\n---\s*\n', content, re.DOTALL)
        if fm_match:
            try:
                frontmatter = yaml.safe_load(fm_match.group(1))
            except yaml.YAMLError:
                issues.append("Invalid YAML frontmatter")

        # 2. Check Meta Description
        if not frontmatter.get("description"):
            issues.append("Missing description in frontmatter")
        elif len(frontmatter["description"]) < 50:
            issues.append(f"Description too short ({len(frontmatter['description'])} chars)")
        elif len(frontmatter["description"]) > 160:
            issues.append(f"Description too long ({len(frontmatter['description'])} chars)")

        # 3. Check Title
        if not frontmatter.get("title"):
            issues.append("Missing title in frontmatter")

        # 4. Check Keyword Density (Target: 'AI', 'Agency', 'Agent')
        body = content[fm_match.end():] if fm_match else content
        keywords = ["AI", "Agency", "Agent", "Automation", "Workflow"]
        found_keywords = {kw: len(re.findall(rf"\b{kw}\b", body, re.IGNORECASE)) for kw in keywords}

        total_kws = sum(found_keywords.values())
        if total_kws == 0:
            issues.append(f"Zero keyword density for targets: {', '.join(keywords)}")

        # 5. Check Image Alts
        img_matches = re.findall(r'!\[(.*?)\]', body)
        for alt in img_matches:
            if not alt.strip():
                issues.append("Found image with missing Alt text")

        return {
            "file": str(path.relative_to(os.getcwd())),
            "title": frontmatter.get("title", "Unknown"),
            "issues": issues,
            "keyword_counts": found_keywords
        }

    def generate_report(self, output_path: str = "reports/marketing/seo_audit.json"):
        report_path = Path(output_path)
        report_path.parent.mkdir(parents=True, exist_ok=True)

        import json
        with open(report_path, "w") as f:
            json.dump({
                "timestamp": Path().stat().st_mtime, # Mock timestamp for now
                "total_pages_audited": len(list(self.docs_path.glob("**/*.md"))),
                "pages_with_issues": len(self.results),
                "audit_results": self.results
            }, f, indent=2)

        print(f"âœ… SEO Audit complete. Report saved to {output_path}")

if __name__ == "__main__":
    auditor = SEOAuditor()
    auditor.run_audit()
    auditor.generate_report()
